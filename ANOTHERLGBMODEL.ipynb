{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "kernel37.07LGBAZER.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Az-Ks/AirQo-Ugandan-Air-Quality-Forecast/blob/master/ANOTHERLGBMODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDcv3QxAxxUb",
        "colab_type": "text"
      },
      "source": [
        "# PLEASE MAKE SURE TO RUN THIS ON KAGGLE TO GET THE SAME SCORE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "HN3OBq3gxu5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "M_fa5gkqxu5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import math\n",
        "import random\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "import category_encoders as ce\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "1W0PjzQixu5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import Lasso, LassoCV\n",
        "from sklearn.ensemble import RandomForestRegressor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "juUsndZAxu5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgbm \n",
        "import xgboost as xgb\n",
        "import catboost as cat\n",
        "from catboost import CatBoostRegressor, Pool, CatBoostClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PlwDxh2Axu5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 2020\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "nyo1ql9pxu5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('MODELS/', exist_ok=True)\n",
        "os.makedirs('/DATASET/CSV/', exist_ok=True)\n",
        "os.makedirs('/DATASET/ZIP/', exist_ok=True)\n",
        "os.makedirs('/DATASET/DOWNLOAD/', exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "s7MPyZf-xu5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mapper = {\n",
        "    \"GOOD\": 0,\n",
        "    \"MODERATE\": 1,\n",
        "    \"SENSITIVE\": 2,\n",
        "    \"UNHEALTHY\": 3,\n",
        "    \"V_UNHEALTHY\": 4,\n",
        "    \"HAZARDOUS\": 5\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bcQN-kcrxu5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categorize(target):\n",
        "  if target <= 12:\n",
        "    return \"GOOD\"\n",
        "  elif target <=35:\n",
        "    return \"MODERATE\"\n",
        "  elif target <= 55:\n",
        "    return \"SENSITIVE\"\n",
        "  elif target <= 150:\n",
        "    return \"UNHEALTHY\"\n",
        "  elif target <= 250:\n",
        "    return \"V_UNHEALTHY\"\n",
        "  else:\n",
        "    return \"HAZARDOUS\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bP_lms_Cxu5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_into_days(df, features, days=5):\n",
        "  width = 24\n",
        "  for feature in features:\n",
        "    for day in range(days):\n",
        "      df[feature+'_day_'+str(day)] = df[feature].apply(lambda x: x[day*width:(day+1)*width])\n",
        "    df[feature+'_target_reading_day'] = df[feature].apply(lambda x: x[-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "izS1G2WKxu5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# covert features  fron string to List of values \n",
        "def replace_nan(x):\n",
        "    if x==\" \":\n",
        "        return np.nan\n",
        "    else :\n",
        "        return float(x)    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_Mhiv4vXxu5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def aggregate_features(x,col_name):\n",
        "    x[\"max_\"+col_name]=x[col_name].apply(np.max)\n",
        "    x[\"min_\"+col_name]=x[col_name].apply(np.min)\n",
        "    x[\"mean_\"+col_name]=x[col_name].apply(np.mean)\n",
        "    x[\"std_\"+col_name]=x[col_name].apply(np.std)\n",
        "    x[\"var_\"+col_name]=x[col_name].apply(np.var)\n",
        "    x[\"median_\"+col_name]=x[col_name].apply(np.median)\n",
        "    x[\"ptp_\"+col_name]=x[col_name].apply(np.ptp)\n",
        "    return x  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XFoIoSlvxu5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_nan_values(x):\n",
        "    strict = [e for e in x if not math.isnan(e)]\n",
        "    if len(strict) == 0:\n",
        "      strict = [np.nan]\n",
        "    return strict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FM4Vhiz2xu5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metric(y,x):\n",
        "    return np.sqrt(mean_squared_error(x,y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xY1VTpUwxu5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_function(model,train,test,params,other_params,target_name,features,metric, model_name):\n",
        "    folds_num=train.fold.nunique()\n",
        "    validation=train[[id_name,\"fold\",target_name]].copy()\n",
        "    validation[\"pred_\"+target_name]=0\n",
        "    sub=test[[id_name]].copy()\n",
        "    feat_imps = pd.DataFrame()\n",
        "    feat_imps['Features'] = features\n",
        "    \n",
        "    for fold in np.sort(train.fold.unique()):\n",
        "        print(\"#\"*50+\" {} \".format(fold)+\"#\"*50)\n",
        "        os.makedirs(\"model_save/{}/{}/{}\".format(model_name,Experiment_name,str(int(fold))), exist_ok=True)\n",
        "        X_train=train[train.fold!=fold]\n",
        "        X_val=train[train.fold==fold]\n",
        "        \n",
        "        train_pred,validation_pred,test_pred,feat_imp=model(X_train,X_val,test,params,other_params)\n",
        "\n",
        "        validation.loc[validation.fold==fold,\"pred_\"+target_name]=validation_pred\n",
        "        sub[target_name]=test_pred/folds_num\n",
        "        train_score=metric(X_train[target_name],train_pred)\n",
        "        val_score=metric(X_val[target_name],validation_pred)\n",
        "        feat_imps[fold] = feat_imp\n",
        "        print(\"train score : {} validation score : {}\".format(round(train_score,4),round(val_score,4)))\n",
        "    \n",
        "    final_validation_score=metric(validation[target_name],validation[\"pred_\"+target_name])\n",
        "    print(\"final validation score : {}\".format(final_validation_score))\n",
        "        \n",
        "    return sub,validation,final_validation_score,feat_imps\n",
        "\n",
        "def lgbm_model(X_train,X_val,X_test,params,other_params):\n",
        "    dtrain = lgbm.Dataset(data=X_train[features], label=X_train[target_name], feature_name=features)\n",
        "    dval = lgbm.Dataset(data=X_val[features], label=X_val[target_name], feature_name=features)\n",
        "\n",
        "    model = lgbm.train(\n",
        "        params=params,\n",
        "        train_set=dtrain,\n",
        "        num_boost_round=other_params[\"num_boost_round\"],\n",
        "        valid_sets=(dtrain, dval),\n",
        "        early_stopping_rounds=other_params[\"early_stopping_rounds\"],\n",
        "        verbose_eval=other_params[\"verbose_eval\"],\n",
        "    )\n",
        "    best_iteration = model.best_iteration\n",
        "    train_pred=model.predict(X_train[features], num_iteration=best_iteration)\n",
        "    validation_pred=model.predict(X_val[features], num_iteration=best_iteration)\n",
        "    test_pred=model.predict(test[features], num_iteration=best_iteration)\n",
        "    feat_imp = model.feature_importance(iteration=best_iteration)\n",
        "        \n",
        "    return train_pred,validation_pred,test_pred, feat_imp\n",
        "\n",
        "def cat_model(X_train,X_val,X_test,params,other_params):\n",
        "    dtrain = Pool(data=X_train[features], label=X_train[target_name], feature_names=features)\n",
        "    dval = Pool(data=X_val[features], label=X_val[target_name], feature_names=features)\n",
        "\n",
        "    model = CatBoostRegressor(**params)\n",
        "    model.fit(dtrain,\n",
        "              eval_set=[dval],\n",
        "              use_best_model=True,\n",
        "              verbose_eval=other_params[\"verbose_eval\"],\n",
        "    )\n",
        "\n",
        "    best_iteration = model.best_iteration_\n",
        "    train_pred = model.predict(X_train[features])\n",
        "    validation_pred = model.predict(X_val[features])\n",
        "    test_pred = model.predict(test[features])\n",
        "    feat_imp = model.feature_importances_\n",
        "        \n",
        "    return train_pred,validation_pred,test_pred, feat_imp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6zM5oaqPxu5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = ['location', 'loc_altitude', 'km2', 'aspect',\n",
        "       'dist_trunk', 'dist_primary', 'dist_secondary',\n",
        "       'dist_tertiary', 'dist_unclassified', 'dist_residential', 'popn', 'hh',\n",
        "       'hh_cook_charcoal', 'hh_cook_firewood', 'hh_burn_waste']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FAo46IrOxu5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('../input/airqo-ugandan-air-quality-forecast-challenge-zindi/Train (1).csv')\n",
        "test = pd.read_csv('../input/airqo-ugandan-air-quality-forecast-challenge-zindi/Test (1).csv')\n",
        "meta = pd.read_csv('../input/airqo-ugandan-air-quality-forecast-challenge-zindi/airqo_metadata.csv', usecols=cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EWn__niTxu5t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sns.barplot(x='location', y='target', data=train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6j6g4kIBxu5v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = [\"temp\", \"precip\", \"rel_humidity\", \"wind_dir\", \"wind_spd\", \"atmos_press\"]\n",
        "\n",
        "days_features = [\n",
        "'temp_day_0', 'temp_day_1', 'temp_day_2', 'temp_day_3', 'temp_day_4', \n",
        "'precip_day_0', 'precip_day_1', 'precip_day_2', 'precip_day_3','precip_day_4',\n",
        "'rel_humidity_day_0','rel_humidity_day_1', 'rel_humidity_day_2', 'rel_humidity_day_3','rel_humidity_day_4',\n",
        "'wind_dir_day_0', 'wind_dir_day_1', 'wind_dir_day_2', 'wind_dir_day_3','wind_dir_day_4',\n",
        "'wind_spd_day_0','wind_spd_day_1', 'wind_spd_day_2', 'wind_spd_day_3', 'wind_spd_day_4',\n",
        "'atmos_press_day_0', 'atmos_press_day_1','atmos_press_day_2', 'atmos_press_day_3', 'atmos_press_day_4']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eGv82_T5xu5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for feature in features :\n",
        "    train[feature] = train[feature].apply(lambda x: [ replace_nan(X) for X in x.replace(\"nan\",\" \").split(\",\")])\n",
        "    test[feature] = test[feature].apply(lambda x: [ replace_nan(X)  for X in x.replace(\"nan\",\" \").split(\",\")])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "it6idKZ4xu5z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datav1 = pd.concat([train, test],sort=False).reset_index(drop=True)\n",
        "datav2 = datav1.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6cYe2pCDxu51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col_name in tqdm(features):\n",
        "  split_into_days(datav1, features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9fVk3hRyxu53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col_name in tqdm(days_features):\n",
        "    datav1[col_name] = datav1[col_name].apply(remove_nan_values)\n",
        "\n",
        "for col_name in tqdm(days_features):\n",
        "    datav1 = aggregate_features(datav1,col_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PlC9yiZ1xu54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col_name in tqdm(features):\n",
        "    datav1[col_name] = datav1[col_name].apply(remove_nan_values)\n",
        "\n",
        "for col_name in tqdm(features):\n",
        "    datav1 = aggregate_features(datav1,col_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2SoIHewUxu56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for feat in features:\n",
        "  for i in range(len(datav2.loc[1, features[0]])):\n",
        "    datav2[feat+f'_{i}'] = datav2[feat].apply(lambda x: x[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5TVE9KpIxu57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datav1.drop(features+days_features, axis=1, inplace=True)\n",
        "datav2.drop(features+['target', 'ID','location'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "S65anRC0xu59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.concat([datav1, datav2], axis=1)\n",
        "#data = datav1.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Xo0WMKN2xu5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "oe = ce.OrdinalEncoder(cols=['location'])\n",
        "data['binned_location'] = oe.fit_transform(data['location'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "PxY9NNO4xu6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta.fillna(-9999, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "48jydDiRxu6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "aggs = {\n",
        "    'binned_location': ['count'],\n",
        "    'target': ['mean', 'min', 'max', 'std', 'quantile', 'sum'],\n",
        "\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "oPKGrSXyxu6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta_stats = data.groupby('location').agg(aggs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZEdUf6frxu6G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta_stats = meta_stats.merge(meta, how='inner', on='location')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4IrEOEUmxu6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta_stats.rename(\n",
        "    columns = {\n",
        "        ('binned_location', 'count') : 'count',\n",
        "        ('target', 'mean') : 'mean_target',            \n",
        "        ('target', 'min') : 'min_target',\n",
        "        ('target', 'max') : 'max_target',\n",
        "        ('target', 'std') : 'std_target',\n",
        "        ('target', 'quantile') : 'quantile_target',\n",
        "        ('target', 'sum') : 'sum_target'\n",
        "    },\n",
        "    inplace=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pFljrdYgxu6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta_stats['mean_pm2.5_per_km2'] = meta_stats['mean_target']/meta_stats['km2']\n",
        "meta_stats['sum_pm2.5_per_km2'] = meta_stats['sum_target']/meta_stats['km2']\n",
        "meta_stats['device_per_km2'] = meta_stats['count']/meta_stats['km2']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Nvdl8aXDxu6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "meta_stats['sum_target'] = meta_stats['sum_target'].apply(np.log2)\n",
        "meta_stats['sum_pm2.5_per_km2'] = meta_stats['sum_pm2.5_per_km2'].apply(np.log2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zmF8CGw0xu6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.merge(meta_stats, how='left', on=['location'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "BvciyhPUxu6O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['mean_temp_day_3']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NVKgBcCBxu6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hum_features =  list(data.filter(regex='rel_humidity_.*').columns)\n",
        "temp_features = list( data.filter(regex='temp_.*').columns)  \n",
        "precip_features =  list(data.filter(regex='precip.*').columns)\n",
        "winddir_features = list( data.filter(regex='wind_dir_.*').columns)\n",
        "windspead_features = list( data.filter(regex='wind_spd_.*').columns)\n",
        "atm_features =  list(data.filter(regex='atmos_press_.*').columns)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "hum_features= hum_features[36:]\n",
        "temp_features=temp_features[36:] \n",
        "precip_features=precip_features[31:]\n",
        "winddir_features=winddir_features[36:]\n",
        "windspead_features=windspead_features[36:]\n",
        "atm_features=atm_features[36:]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data[hum_features]= data[hum_features].apply(lambda x: x.fillna(x.mean()),axis=1)\n",
        "\n",
        "\n",
        "\n",
        "data[temp_features]= data[temp_features].apply(lambda x: x.fillna(x.mean()),axis=1)\n",
        "\n",
        "\n",
        "data[precip_features]= data[precip_features].apply(lambda x: x.fillna(float(0.0)),axis=1)\n",
        "\n",
        "\n",
        "\n",
        "data[winddir_features]= data[winddir_features].apply(lambda x: x.fillna(x.mean()),axis=1)\n",
        "\n",
        "\n",
        "\n",
        "data[windspead_features]= data[windspead_features].apply(lambda x: x.fillna(x.mean()),axis=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "data[atm_features]= data[atm_features].apply(lambda x: x.fillna(x.mean()),axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AafXo5ESxu6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['relation1'] = data['wind_spd_118'] +data['wind_spd_119'] +data['wind_spd_120']\n",
        "data['relation2'] = data['temp_89'] + data['temp_95'] + data['temp_48'] +data['temp_70'] + data['temp_88'] + data['temp_72']\n",
        "data['relation3'] = data['rel_humidity_112'] + data['rel_humidity_113'] + data['rel_humidity_102'] + data['rel_humidity_42'] + data['rel_humidity_3'] \n",
        "data['relation4'] = data['atmos_press_103'] + data['atmos_press_7'] +data['atmos_press_10'] +data['atmos_press_109'] +data['atmos_press_116']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uN7EC45bxu6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wind_dir_feature_ =  list(data.filter(regex='wind_dir.*').columns)\n",
        "len([x for x in data.columns if 'wind_dir' in x]) , len(wind_dir_feature_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xRQys-BFxu6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def radian_conv(degree):\n",
        "    \"\"\"\n",
        "    Return radian.\n",
        "    \"\"\"\n",
        "    return  np.radians(degree) \n",
        "\n",
        "\n",
        "\n",
        "for col in wind_dir_feature_ :\n",
        "  \n",
        "  data[col] = data[col].apply(radian_conv)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ko3yQM7bxu6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = data[data.target.notnull()].reset_index(drop=True)\n",
        "test = data[data.target.isna()].reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5IZ9qeRnxu6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "to_drop = ['min_precip_day_0', 'min_precip_day_1', 'min_precip_day_2',\n",
        "       'min_precip_day_3', 'min_precip_day_4', 'min_precip', \n",
        "       'median_precip_day_0', 'median_precip_day_1', 'median_precip_day_2',\n",
        "       'median_precip_day_3', 'median_precip_day_4', 'median_precip',\n",
        "       ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fS0fK_LUxu6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.drop(labels=to_drop, axis=1, inplace=True)\n",
        "test.drop(labels=to_drop, axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "01RV_1ynxu6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = train.columns.difference(['ID', 'target', 'binned_location'])\n",
        "select_features = train.columns.difference(['ID', 'target', 'location'])\n",
        "target = 'target'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DG4ZV1EZxu6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "best_features = ['atmos_press_1', 'atmos_press_10', 'atmos_press_103',\n",
        "       'atmos_press_104', 'atmos_press_105', 'atmos_press_109',\n",
        "       'atmos_press_110', 'atmos_press_115', 'atmos_press_116',\n",
        "       'atmos_press_14', 'atmos_press_19', 'atmos_press_2',\n",
        "       'atmos_press_20', 'atmos_press_21', 'atmos_press_25',\n",
        "       'atmos_press_26', 'atmos_press_27', 'atmos_press_28',\n",
        "       'atmos_press_3', 'atmos_press_31', 'atmos_press_32',\n",
        "       'atmos_press_33', 'atmos_press_37', 'atmos_press_38',\n",
        "       'atmos_press_39', 'atmos_press_43', 'atmos_press_44',\n",
        "       'atmos_press_50', 'atmos_press_51', 'atmos_press_52',\n",
        "       'atmos_press_56', 'atmos_press_57', 'atmos_press_61',\n",
        "       'atmos_press_62', 'atmos_press_67', 'atmos_press_68',\n",
        "       'atmos_press_7', 'atmos_press_75', 'atmos_press_8',\n",
        "       'atmos_press_80', 'atmos_press_81', 'atmos_press_86',\n",
        "       'atmos_press_9', 'atmos_press_91', 'atmos_press_92',\n",
        "       'atmos_press_93', 'atmos_press_98', 'atmos_press_99',\n",
        "       'hh_burn_waste', 'max_atmos_press', 'max_precip',\n",
        "       'max_rel_humidity', \n",
        "        'max_rel_humidity_day_2',\n",
        "        'max_temp', 'max_wind_dir',\n",
        "        'max_wind_dir_day_2',\n",
        "        'max_wind_spd',\n",
        "       'mean_atmos_press', 'mean_precip', 'mean_rel_humidity',\n",
        "       \n",
        "       \n",
        "       'mean_target', 'mean_temp_day_2',\n",
        "       'mean_wind_dir',\n",
        "       'mean_wind_dir_day_2',\n",
        "        'mean_wind_spd',\n",
        "        'median_atmos_press',\n",
        "       'median_rel_humidity', \n",
        "       'median_rel_humidity_day_2', \n",
        "       'median_temp',\n",
        "       'median_temp_day_2', \n",
        "       'median_wind_dir',\n",
        "        'median_wind_dir_day_2',\n",
        "       \n",
        "       'median_wind_spd',\n",
        "       'median_wind_spd_day_2', \n",
        "        'min_atmos_press_day_2',\n",
        "        'min_rel_humidity',\n",
        "        'min_temp',\n",
        "        'min_temp_day_2',\n",
        "        'min_wind_dir',\n",
        "       \n",
        "       'min_wind_spd', 'min_wind_spd_day_2',\n",
        "        'ptp_atmos_press',\n",
        "       \n",
        "     'ptp_precip', 'ptp_rel_humidity',\n",
        "        'ptp_wind_dir',\n",
        "        'ptp_wind_spd',\n",
        "       'rel_humidity_102', 'rel_humidity_112', 'rel_humidity_113',\n",
        "       'rel_humidity_114', 'rel_humidity_3', 'rel_humidity_42',\n",
        "       'rel_humidity_63', 'rel_humidity_78', 'std_atmos_press',\n",
        "       'std_precip', 'std_rel_humidity', 'std_wind_dir',\n",
        "        'std_wind_spd', 'temp_0', 'temp_1',\n",
        "       'temp_102', 'temp_113', 'temp_114', 'temp_118', 'temp_120',\n",
        "       'temp_16', 'temp_17', 'temp_2', 'temp_20', 'temp_22', 'temp_23',\n",
        "       'temp_24', 'temp_25', 'temp_30', 'temp_40', 'temp_41', 'temp_48',\n",
        "       'temp_49', 'temp_5', 'temp_50', 'temp_54', 'temp_64', 'temp_70',\n",
        "       'temp_71', 'temp_72', 'temp_78', 'temp_88', 'temp_89', 'temp_92',\n",
        "       'temp_94', 'temp_95', 'temp_97', 'temp_target_reading_day',\n",
        "       'var_atmos_press', 'var_precip', 'var_rel_humidity', 'var_temp',\n",
        "       'var_wind_dir',  'var_wind_spd',\n",
        "       'wind_spd_108', 'wind_spd_118', 'wind_spd_119', 'wind_spd_120',\n",
        "       'wind_spd_29', 'wind_spd_target_reading_day' ,\n",
        "                 'relation1','relation2','relation3',\n",
        "                ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Se050WX6xu6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fold = KFold(n_splits=20, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bGOgFqJexu6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgb\n",
        "params = {\n",
        "    'objective' :'regression',\n",
        "    'learning_rate' : 0.1,\n",
        "    'num_iterations': 1500,\n",
        "    'max_bins': 150, \n",
        "    'max_depth' :7 ,\n",
        "    'num_leaves' : 200,\n",
        "    'feature_fraction': 0.64, \n",
        "    'bagging_fraction': 0.8, \n",
        "    'bagging_freq':1,\n",
        "    'boosting_type' : 'gbdt',\n",
        "    'metric': 'rmse' ,\n",
        "     'min_data_in_leaf':15,\n",
        "    'reg_lambda' :150\n",
        "}\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ic2XJvDoxu6p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_preds = []\n",
        "score_oofs = []\n",
        "feats = pd.DataFrame({'features': best_features}) #You can change \n",
        "\n",
        "for i, (tr, vr) in enumerate(fold.split(train)):\n",
        "  X, Y = train.loc[tr, best_features], train.loc[tr, target]\n",
        "  x, y = train.loc[vr, best_features], train.loc[vr, target]\n",
        "\n",
        "  model = lgb.LGBMRegressor(**params)\n",
        "  model.fit(X, Y, eval_set=[(x,y)], verbose=100, early_stopping_rounds=200)\n",
        "  pred = model.predict(x)\n",
        "  test_pred = model.predict(test[best_features])\n",
        "  sc = metric(y, pred)\n",
        "  score_oofs.append(sc)\n",
        "  test_preds.append(test_pred)\n",
        "  feats[f'Fold {i}'] = model.feature_importances_\n",
        "  # print('RMSE : {}'.format(sc))\n",
        "feats['Importances'] = feats.mean(axis=1)\n",
        "print()\n",
        "print('CV RMSE : {}'.format(np.mean(score_oofs, axis=0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "H0TQsVrBxu6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('CV RMSE : {}'.format(np.mean(score_oofs, axis=0)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sGBtFpTyXfT",
        "colab_type": "text"
      },
      "source": [
        "## ON KAGGLE CV RMSE ==22.69329469880266"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zsZqw6p_xu6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test[target] = np.mean(test_preds, axis=0)\n",
        "test[['ID', target]].to_csv('ANOTHERLGB.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0vjmYYbqxu6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feats.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xeyGQnUIxu6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(20,40))\n",
        "sns.barplot(x='Importances', y='features', data=feats.sort_values(by='Importances', ascending=False));"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}